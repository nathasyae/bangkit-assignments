{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gzd16YQmlnDW"
   },
   "source": [
    "# Fake News Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OkUZMDVlnDZ"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "PsDi-32LlnDZ",
    "outputId": "dc088a9d-7f8f-42fe-d720-0938dfd29ef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "8r6dzr1slnDp",
    "outputId": "2bed2f63-0598-412b-c8eb-964e70130775"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nathasya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "stop = list(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, log_loss,confusion_matrix, roc_curve, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3N5anl-plnDv"
   },
   "outputs": [],
   "source": [
    "fake = pd.read_csv(\"Fake.csv\")\n",
    "true = pd.read_csv(\"True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8U2G8XNhlnD0"
   },
   "outputs": [],
   "source": [
    "fake[\"type\"] = 1\n",
    "true[\"type\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-jZbufRlnD4"
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for text in true[\"text\"]:\n",
    "  temp = re.sub(r\"^.*Reuters+\\W+[-]+\\W\", r\"\", text)\n",
    "  lst.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-RT9Ze0flnD7"
   },
   "outputs": [],
   "source": [
    "true[\"text\"] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHWKdDFGlnD-"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([fake,true], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "4HnbJGAslnEC",
    "outputId": "45482ad2-ba80-4085-901f-16fe7d416d52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  type  \n",
       "0  December 31, 2017     1  \n",
       "1  December 31, 2017     1  \n",
       "2  December 30, 2017     1  \n",
       "3  December 29, 2017     1  \n",
       "4  December 25, 2017     1  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>'Fully committed' NATO backs new U.S. approach...</td>\n",
       "      <td>NATO allies on Tuesday welcomed President Dona...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>LexisNexis, a provider of legal, regulatory an...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>Minsk cultural hub becomes haven from authorities</td>\n",
       "      <td>In the shadow of disused Soviet-era factories ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n",
       "      <td>Vatican Secretary of State Cardinal Pietro Par...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n",
       "      <td>Indonesia will buy 11 Sukhoi fighter jets wort...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "44893  'Fully committed' NATO backs new U.S. approach...   \n",
       "44894  LexisNexis withdrew two products from Chinese ...   \n",
       "44895  Minsk cultural hub becomes haven from authorities   \n",
       "44896  Vatican upbeat on possibility of Pope Francis ...   \n",
       "44897  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text    subject  \\\n",
       "44893  NATO allies on Tuesday welcomed President Dona...  worldnews   \n",
       "44894  LexisNexis, a provider of legal, regulatory an...  worldnews   \n",
       "44895  In the shadow of disused Soviet-era factories ...  worldnews   \n",
       "44896  Vatican Secretary of State Cardinal Pietro Par...  worldnews   \n",
       "44897  Indonesia will buy 11 Sukhoi fighter jets wort...  worldnews   \n",
       "\n",
       "                   date  type  \n",
       "44893  August 22, 2017      0  \n",
       "44894  August 22, 2017      0  \n",
       "44895  August 22, 2017      0  \n",
       "44896  August 22, 2017      0  \n",
       "44897  August 22, 2017      0  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCM4UOc7lnE_"
   },
   "source": [
    "## Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jInpTnGMlnE_"
   },
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMgPDL4MlnFA"
   },
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "  url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "  return url.sub(r\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUy6dfrGoA52"
   },
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "  html = re.compile(r\"<.*?>\")\n",
    "  return html.sub(r\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wEyv0skSoC4y"
   },
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxbyA1OVoElc"
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "  punct = re.compile(r'[!\"#$%&\\\\\\'()*+,-./:;<=>?@[\\\\\\]^_`{|}~]')\n",
    "  return punct.sub(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-xxWdEVoIrR"
   },
   "outputs": [],
   "source": [
    "def spell_checking(text):\n",
    "\n",
    "  spell = SpellChecker()\n",
    "  correct = []\n",
    "\n",
    "  miss_spell = spell.unknown(text.split())\n",
    "\n",
    "  for word in text.split():\n",
    "    if word in miss_spell:\n",
    "      correct.append(spell.correction(word))\n",
    "    else:\n",
    "      correct.append(word)\n",
    "  \n",
    "  return \" \".join(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9jxNVggoMZT"
   },
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "  temp = [word for word in text if word not in stop]\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jMhq4esoN0s"
   },
   "outputs": [],
   "source": [
    "def remove_single_alphabet(text):\n",
    "  temp = [word for word in text if word not in string.ascii_lowercase]\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lower(text):\n",
    "#     temp = [word.lowe() for word in text]\n",
    "#     return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4lFb5xFoQeW"
   },
   "outputs": [],
   "source": [
    "# def cleaning_text(text):\n",
    "#   text = text.apply(lambda x : remove_url)\n",
    "#   text = text.apply(lambda x : remove_html)\n",
    "#   text = text.apply(lambda x : remove_emoji)\n",
    "#   text = text.apply(lambda x : lower)\n",
    "#   text = text.apply(lambda x : remove_punct)\n",
    "#   # text = text.apply(lambda x : spell_checking(x))\n",
    "#   return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "  text = text.apply(lambda x : remove_url(x))\n",
    "  text = text.apply(lambda x : remove_html(x))\n",
    "  text = text.apply(lambda x : remove_emoji(x))\n",
    "  text = text.apply(lambda x : x.lower())\n",
    "  text = text.apply(lambda x : remove_punct(x))\n",
    "  # text = text.apply(lambda x : spell_checking(x))\n",
    "  return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(text):\n",
    "  return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = cleaning_text(df[\"text\"])\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x : x.lower())\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x : x.split())\n",
    "df[\"text\"] = df[\"text\"].apply(remove_stopword)\n",
    "df[\"text\"] = df[\"text\"].apply(remove_single_alphabet)\n",
    "df[\"text\"] = df[\"text\"].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        donald trump wish americans happy new year lea...\n",
       "1        house intelligence committee chairman devin nu...\n",
       "2        friday revealed former milwaukee sheriff david...\n",
       "3        christmas day donald trump announced would bac...\n",
       "4        pope francis used annual christmas day message...\n",
       "                               ...                        \n",
       "44893    nato allies tuesday welcomed president donald ...\n",
       "44894    lexisnexis provider legal regulatory business ...\n",
       "44895    shadow disused sovietera factories minsk stree...\n",
       "44896    vatican secretary state cardinal pietro paroli...\n",
       "44897    indonesia buy 11 sukhoi fighter jets worth 114...\n",
       "Name: text, Length: 44898, dtype: object"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nathasya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nathasya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def stem(text):\n",
    "#     token_words = word_tokenize(sentence)\n",
    "#     token_words\n",
    "#     stem_sentence={}\n",
    "    stem_result = []\n",
    "#           temp = [word for word in text if word not in stop]\n",
    "#   return temp\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    for word in text:\n",
    "        stem_result.append(stemmer.stem(word))\n",
    "    return stem_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemma(text):\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "#     token_words = word_tokenize(sentence)\n",
    "#     token_words\n",
    "    lem_result=[]\n",
    "    \n",
    "    for word in text:\n",
    "        lem_result.append(lemmatizer.lemmatize(word))\n",
    "    return lem_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"text\"] = cleaning_text(df[\"text\"])\n",
    "# # df[\"text\"] = df[\"text\"].apply(lambda x : x.lower())\n",
    "# # df[\"text\"] = df[\"text\"].apply(lambda x : x.split())\n",
    "# # df[\"text\"] = df[\"text\"].apply(remove_stopword)\n",
    "# df[\"text\"] = df[\"text\"].apply(remove_single_alphabet)\n",
    "# df[\"text\"] = df[\"text\"].apply(stem)\n",
    "# df[\"text\"] = df[\"text\"].apply(lemma)\n",
    "# df[\"text\"] = df[\"text\"].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ES1tLalioScQ"
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = cleaning_text(df[\"text\"])\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x : x.lower())\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x : x.split())\n",
    "df[\"text\"] = df[\"text\"].apply(remove_stopword)\n",
    "df[\"text\"] = df[\"text\"].apply(remove_single_alphabet)\n",
    "df[\"text\"] = df[\"text\"].apply(stem)\n",
    "df[\"text\"] = df[\"text\"].apply(lemma)\n",
    "df[\"text\"] = df[\"text\"].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hh77BeahoV_R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "F2nl37aMoY0B",
    "outputId": "d9a2a3a6-c863-46c1-a0c5-5943c0933282"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        donald trump wish american happi new year leav...\n",
       "1        hous intellig committe chairman devin nune go ...\n",
       "2        friday reveal former milwauke sheriff david cl...\n",
       "3        christma day donald trump announc would back w...\n",
       "4        pope franci use annual christma day messag reb...\n",
       "                               ...                        \n",
       "44893    nato alli tuesday welcom presid donald trump d...\n",
       "44894    lexisnexi provid legal regulatori busi inform ...\n",
       "44895    shadow disus sovietera factori minsk street li...\n",
       "44896    vatican secretari state cardin pietro parolin ...\n",
       "44897    indonesia buy 11 sukhoi fighter jet worth 114 ...\n",
       "Name: text, Length: 44898, dtype: object"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeuciEkdlnFD"
   },
   "source": [
    "### Splitting Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbfyflJrocg3"
   },
   "outputs": [],
   "source": [
    "# Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W7QmP5EVlnFD"
   },
   "source": [
    "## Feature Extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BjpMnXpDtLK2"
   },
   "source": [
    "### Bag Of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XS-HtFobtES2"
   },
   "outputs": [],
   "source": [
    "# Bag of Word\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,\n",
    "                             max_features = 5000)\n",
    "\n",
    "train_features = vectorizer.fit_transform(X_train)\n",
    "train_features = train_features.toarray()\n",
    "\n",
    "test_features = vectorizer.transform(X_test)\n",
    "test_features = test_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRBfrE67lnFE"
   },
   "source": [
    "### GloVe Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "EnmLxcyh5zMC",
    "outputId": "026cb7e4-0ea4-4203-8403-264abae4b7b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nathasya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKsp6Xkn545P"
   },
   "outputs": [],
   "source": [
    "# ps = PorterStemmer() \n",
    "\n",
    "def create_corpus(df):\n",
    "  corpus = []\n",
    "\n",
    "  for text in tqdm(df[\"text\"]):\n",
    "    words = [word.lower() for word in word_tokenize(text) if ((word.isalpha()) & (word not in stop))]\n",
    "    corpus.append(words)\n",
    "  \n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "u1DjU2tG55yB",
    "outputId": "c8dc302d-1e7a-47a9-f5ec-455b93ef741b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 44898/44898 [02:40<00:00, 279.39it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = create_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "XGy7Ds8j5606",
    "outputId": "21522dd0-04c5-4e96-b3b5-0cbb61004136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading glove-global-vectors-for-word-representation.zip to D:\\bangkit\\individual assignments\\data preparation\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/458M [00:00<?, ?B/s]\n",
      "  0%|          | 1.00M/458M [00:00<02:19, 3.44MB/s]\n",
      "  0%|          | 2.00M/458M [00:00<02:16, 3.51MB/s]\n",
      "  1%|          | 3.00M/458M [00:00<02:08, 3.72MB/s]\n",
      "  1%|          | 4.00M/458M [00:01<02:13, 3.57MB/s]\n",
      "  1%|1         | 5.00M/458M [00:01<02:14, 3.53MB/s]\n",
      "  1%|1         | 6.00M/458M [00:02<02:55, 2.71MB/s]\n",
      "  2%|1         | 7.00M/458M [00:02<02:59, 2.63MB/s]\n",
      "  2%|1         | 8.00M/458M [00:02<02:58, 2.64MB/s]\n",
      "  2%|1         | 9.00M/458M [00:03<04:13, 1.86MB/s]\n",
      "  2%|2         | 10.0M/458M [00:04<04:03, 1.93MB/s]\n",
      "  2%|2         | 11.0M/458M [00:04<03:32, 2.20MB/s]\n",
      "  3%|2         | 12.0M/458M [00:04<02:58, 2.62MB/s]\n",
      "  3%|2         | 13.0M/458M [00:05<02:49, 2.75MB/s]\n",
      "  3%|3         | 14.0M/458M [00:05<02:37, 2.95MB/s]\n",
      "  3%|3         | 15.0M/458M [00:05<02:29, 3.11MB/s]\n",
      "  3%|3         | 16.0M/458M [00:06<02:20, 3.29MB/s]\n",
      "  4%|3         | 17.0M/458M [00:06<02:20, 3.28MB/s]\n",
      "  4%|3         | 18.0M/458M [00:06<02:22, 3.23MB/s]\n",
      "  4%|4         | 19.0M/458M [00:07<02:16, 3.38MB/s]\n",
      "  4%|4         | 20.0M/458M [00:07<02:12, 3.45MB/s]\n",
      "  5%|4         | 21.0M/458M [00:07<02:17, 3.32MB/s]\n",
      "  5%|4         | 22.0M/458M [00:07<02:16, 3.35MB/s]\n",
      "  5%|5         | 23.0M/458M [00:08<02:13, 3.41MB/s]\n",
      "  5%|5         | 24.0M/458M [00:08<02:14, 3.38MB/s]\n",
      "  5%|5         | 25.0M/458M [00:08<02:08, 3.53MB/s]\n",
      "  6%|5         | 26.0M/458M [00:09<02:13, 3.40MB/s]\n",
      "  6%|5         | 27.0M/458M [00:09<02:13, 3.40MB/s]\n",
      "  6%|6         | 28.0M/458M [00:09<02:12, 3.41MB/s]\n",
      "  6%|6         | 29.0M/458M [00:10<02:22, 3.16MB/s]\n",
      "  7%|6         | 30.0M/458M [00:10<02:29, 3.01MB/s]\n",
      "  7%|6         | 31.0M/458M [00:10<02:24, 3.10MB/s]\n",
      "  7%|6         | 32.0M/458M [00:11<02:17, 3.25MB/s]\n",
      "  7%|7         | 33.0M/458M [00:11<02:20, 3.17MB/s]\n",
      "  7%|7         | 34.0M/458M [00:11<02:13, 3.32MB/s]\n",
      "  8%|7         | 35.0M/458M [00:12<02:12, 3.36MB/s]\n",
      "  8%|7         | 36.0M/458M [00:12<02:11, 3.37MB/s]\n",
      "  8%|8         | 37.0M/458M [00:12<02:13, 3.31MB/s]\n",
      "  8%|8         | 38.0M/458M [00:13<02:09, 3.40MB/s]\n",
      "  9%|8         | 39.0M/458M [00:13<02:16, 3.21MB/s]\n",
      "  9%|8         | 40.0M/458M [00:13<02:28, 2.95MB/s]\n",
      "  9%|8         | 41.0M/458M [00:14<02:28, 2.95MB/s]\n",
      "  9%|9         | 42.0M/458M [00:14<02:19, 3.13MB/s]\n",
      "  9%|9         | 43.0M/458M [00:14<02:13, 3.27MB/s]\n",
      " 10%|9         | 44.0M/458M [00:14<02:05, 3.46MB/s]\n",
      " 10%|9         | 45.0M/458M [00:15<02:02, 3.54MB/s]\n",
      " 10%|#         | 46.0M/458M [00:15<02:05, 3.45MB/s]\n",
      " 10%|#         | 47.0M/458M [00:15<02:05, 3.43MB/s]\n",
      " 10%|#         | 48.0M/458M [00:16<02:06, 3.41MB/s]\n",
      " 11%|#         | 49.0M/458M [00:16<02:13, 3.22MB/s]\n",
      " 11%|#         | 50.0M/458M [00:16<02:16, 3.14MB/s]\n",
      " 11%|#1        | 51.0M/458M [00:17<02:28, 2.88MB/s]\n",
      " 11%|#1        | 52.0M/458M [00:17<02:13, 3.20MB/s]\n",
      " 12%|#1        | 53.0M/458M [00:17<02:11, 3.23MB/s]\n",
      " 12%|#1        | 54.0M/458M [00:18<02:06, 3.36MB/s]\n",
      " 12%|#2        | 55.0M/458M [00:18<02:04, 3.38MB/s]\n",
      " 12%|#2        | 56.0M/458M [00:18<02:04, 3.39MB/s]\n",
      " 12%|#2        | 57.0M/458M [00:19<02:12, 3.17MB/s]\n",
      " 13%|#2        | 58.0M/458M [00:19<02:06, 3.32MB/s]\n",
      " 13%|#2        | 59.0M/458M [00:19<02:06, 3.29MB/s]\n",
      " 13%|#3        | 60.0M/458M [00:20<02:02, 3.40MB/s]\n",
      " 13%|#3        | 61.0M/458M [00:20<01:56, 3.56MB/s]\n",
      " 14%|#3        | 62.0M/458M [00:20<01:58, 3.50MB/s]\n",
      " 14%|#3        | 63.0M/458M [00:20<01:56, 3.56MB/s]\n",
      " 14%|#3        | 64.0M/458M [00:21<02:03, 3.35MB/s]\n",
      " 14%|#4        | 65.0M/458M [00:21<01:57, 3.50MB/s]\n",
      " 14%|#4        | 66.0M/458M [00:21<01:55, 3.56MB/s]\n",
      " 15%|#4        | 67.0M/458M [00:22<02:00, 3.41MB/s]\n",
      " 15%|#4        | 68.0M/458M [00:22<01:56, 3.51MB/s]\n",
      " 15%|#5        | 69.0M/458M [00:22<01:58, 3.43MB/s]\n",
      " 15%|#5        | 70.0M/458M [00:23<02:00, 3.37MB/s]\n",
      " 16%|#5        | 71.0M/458M [00:23<02:21, 2.86MB/s]\n",
      " 16%|#5        | 72.0M/458M [00:23<02:21, 2.87MB/s]\n",
      " 16%|#5        | 73.0M/458M [00:24<02:16, 2.95MB/s]\n",
      " 16%|#6        | 74.0M/458M [00:24<02:13, 3.03MB/s]\n",
      " 16%|#6        | 75.0M/458M [00:25<02:18, 2.90MB/s]\n",
      " 17%|#6        | 76.0M/458M [00:25<02:30, 2.66MB/s]\n",
      " 17%|#6        | 77.0M/458M [00:26<03:04, 2.17MB/s]\n",
      " 17%|#7        | 78.0M/458M [00:26<02:54, 2.28MB/s]\n",
      " 17%|#7        | 79.0M/458M [00:27<04:08, 1.60MB/s]\n",
      " 17%|#7        | 80.0M/458M [00:28<04:12, 1.57MB/s]\n",
      " 18%|#7        | 81.0M/458M [00:29<04:40, 1.41MB/s]\n",
      " 18%|#7        | 82.0M/458M [00:29<03:43, 1.76MB/s]\n",
      " 18%|#8        | 83.0M/458M [00:30<03:50, 1.71MB/s]\n",
      " 18%|#8        | 84.0M/458M [00:30<03:52, 1.69MB/s]\n",
      " 19%|#8        | 85.0M/458M [00:31<03:48, 1.71MB/s]\n",
      " 19%|#8        | 86.0M/458M [00:31<03:08, 2.06MB/s]\n",
      " 19%|#8        | 87.0M/458M [00:32<02:52, 2.25MB/s]\n",
      " 19%|#9        | 88.0M/458M [00:32<02:42, 2.38MB/s]\n",
      " 19%|#9        | 89.0M/458M [00:32<02:27, 2.62MB/s]\n",
      " 20%|#9        | 90.0M/458M [00:33<02:12, 2.91MB/s]\n",
      " 20%|#9        | 91.0M/458M [00:33<02:15, 2.84MB/s]\n",
      " 20%|##        | 92.0M/458M [00:33<02:11, 2.91MB/s]\n",
      " 20%|##        | 93.0M/458M [00:34<02:07, 2.99MB/s]\n",
      " 21%|##        | 94.0M/458M [00:34<01:59, 3.19MB/s]\n",
      " 21%|##        | 95.0M/458M [00:34<01:57, 3.23MB/s]\n",
      " 21%|##        | 96.0M/458M [00:35<01:54, 3.30MB/s]\n",
      " 21%|##1       | 97.0M/458M [00:35<01:52, 3.36MB/s]\n",
      " 21%|##1       | 98.0M/458M [00:35<01:55, 3.26MB/s]\n",
      " 22%|##1       | 99.0M/458M [00:35<01:52, 3.36MB/s]\n",
      " 22%|##1       | 100M/458M [00:36<01:54, 3.29MB/s] \n",
      " 22%|##2       | 101M/458M [00:36<01:52, 3.32MB/s]\n",
      " 22%|##2       | 102M/458M [00:36<02:00, 3.09MB/s]\n",
      " 22%|##2       | 103M/458M [00:37<02:03, 3.02MB/s]\n",
      " 23%|##2       | 104M/458M [00:37<01:58, 3.12MB/s]\n",
      " 23%|##2       | 105M/458M [00:37<01:54, 3.23MB/s]\n",
      " 23%|##3       | 106M/458M [00:38<01:51, 3.32MB/s]\n",
      " 23%|##3       | 107M/458M [00:38<01:50, 3.34MB/s]\n",
      " 24%|##3       | 108M/458M [00:38<01:48, 3.40MB/s]\n",
      " 24%|##3       | 109M/458M [00:39<01:51, 3.28MB/s]\n",
      " 24%|##4       | 110M/458M [00:39<01:49, 3.35MB/s]\n",
      " 24%|##4       | 111M/458M [00:39<01:47, 3.39MB/s]\n",
      " 24%|##4       | 112M/458M [00:40<01:49, 3.32MB/s]\n",
      " 25%|##4       | 113M/458M [00:40<01:49, 3.29MB/s]\n",
      " 25%|##4       | 114M/458M [00:40<01:42, 3.51MB/s]\n",
      " 25%|##5       | 115M/458M [00:41<01:47, 3.36MB/s]\n",
      " 25%|##5       | 116M/458M [00:41<01:46, 3.38MB/s]\n",
      " 26%|##5       | 117M/458M [00:41<01:51, 3.20MB/s]\n",
      " 26%|##5       | 118M/458M [00:42<01:49, 3.25MB/s]\n",
      " 26%|##5       | 119M/458M [00:42<01:52, 3.16MB/s]\n",
      " 26%|##6       | 120M/458M [00:42<01:52, 3.14MB/s]\n",
      " 26%|##6       | 121M/458M [00:43<02:03, 2.86MB/s]\n",
      " 27%|##6       | 122M/458M [00:43<02:02, 2.89MB/s]\n",
      " 27%|##6       | 123M/458M [00:43<02:00, 2.91MB/s]\n",
      " 27%|##7       | 124M/458M [00:44<02:04, 2.82MB/s]\n",
      " 27%|##7       | 125M/458M [00:44<01:50, 3.15MB/s]\n",
      " 28%|##7       | 126M/458M [00:45<02:13, 2.61MB/s]\n",
      " 28%|##7       | 127M/458M [00:45<01:53, 3.05MB/s]\n",
      " 28%|##7       | 128M/458M [00:45<02:05, 2.75MB/s]\n",
      " 28%|##8       | 129M/458M [00:46<02:00, 2.87MB/s]\n",
      " 28%|##8       | 130M/458M [00:46<01:52, 3.07MB/s]\n",
      " 29%|##8       | 131M/458M [00:46<01:48, 3.15MB/s]\n",
      " 29%|##8       | 132M/458M [00:47<01:48, 3.16MB/s]\n",
      " 29%|##9       | 133M/458M [00:51<07:54, 718kB/s] \n",
      " 29%|##9       | 134M/458M [00:51<06:09, 920kB/s]\n",
      " 29%|##9       | 135M/458M [00:52<05:06, 1.11MB/s]\n",
      " 30%|##9       | 136M/458M [00:52<03:55, 1.43MB/s]\n",
      " 30%|##9       | 137M/458M [00:52<03:12, 1.74MB/s]\n",
      " 30%|###       | 138M/458M [00:52<02:45, 2.02MB/s]\n",
      " 30%|###       | 139M/458M [00:53<02:19, 2.40MB/s]\n",
      " 31%|###       | 140M/458M [00:53<02:04, 2.68MB/s]\n",
      " 31%|###       | 141M/458M [00:53<02:07, 2.61MB/s]\n",
      " 31%|###1      | 142M/458M [00:54<02:00, 2.74MB/s]\n",
      " 31%|###1      | 143M/458M [00:54<01:59, 2.76MB/s]\n",
      " 31%|###1      | 144M/458M [00:54<01:49, 3.01MB/s]\n",
      " 32%|###1      | 145M/458M [00:55<01:41, 3.24MB/s]\n",
      " 32%|###1      | 146M/458M [00:55<01:38, 3.31MB/s]\n",
      " 32%|###2      | 147M/458M [00:55<01:38, 3.32MB/s]\n",
      " 32%|###2      | 148M/458M [00:56<01:38, 3.30MB/s]\n",
      " 33%|###2      | 149M/458M [00:56<01:33, 3.45MB/s]\n",
      " 33%|###2      | 150M/458M [00:56<01:34, 3.42MB/s]\n",
      " 33%|###2      | 151M/458M [00:56<01:38, 3.26MB/s]\n",
      " 33%|###3      | 152M/458M [00:57<01:40, 3.19MB/s]\n",
      " 33%|###3      | 153M/458M [00:57<01:38, 3.23MB/s]\n",
      " 34%|###3      | 154M/458M [00:57<01:40, 3.18MB/s]\n",
      " 34%|###3      | 155M/458M [00:58<01:38, 3.22MB/s]\n",
      " 34%|###4      | 156M/458M [00:58<01:37, 3.23MB/s]\n",
      " 34%|###4      | 157M/458M [00:58<01:32, 3.39MB/s]\n",
      " 35%|###4      | 158M/458M [00:59<01:37, 3.23MB/s]\n",
      " 35%|###4      | 159M/458M [00:59<01:31, 3.42MB/s]\n",
      " 35%|###4      | 160M/458M [00:59<01:33, 3.33MB/s]\n",
      " 35%|###5      | 161M/458M [01:00<01:33, 3.33MB/s]\n",
      " 35%|###5      | 162M/458M [01:00<01:38, 3.15MB/s]\n",
      " 36%|###5      | 163M/458M [01:00<01:33, 3.30MB/s]\n",
      " 36%|###5      | 164M/458M [01:01<01:31, 3.36MB/s]\n",
      " 36%|###6      | 165M/458M [01:01<01:26, 3.54MB/s]\n",
      " 36%|###6      | 166M/458M [01:01<01:31, 3.35MB/s]\n",
      " 36%|###6      | 167M/458M [01:01<01:27, 3.48MB/s]\n",
      " 37%|###6      | 168M/458M [01:02<01:33, 3.24MB/s]\n",
      " 37%|###6      | 169M/458M [01:02<01:41, 2.97MB/s]\n",
      " 37%|###7      | 170M/458M [01:03<01:53, 2.67MB/s]\n",
      " 37%|###7      | 171M/458M [01:03<01:55, 2.61MB/s]\n",
      " 38%|###7      | 172M/458M [01:04<01:55, 2.59MB/s]\n",
      " 38%|###7      | 173M/458M [01:04<01:54, 2.60MB/s]\n",
      " 38%|###7      | 174M/458M [01:04<01:47, 2.76MB/s]\n",
      " 38%|###8      | 175M/458M [01:05<01:37, 3.03MB/s]\n",
      " 38%|###8      | 176M/458M [01:05<01:31, 3.23MB/s]\n",
      " 39%|###8      | 177M/458M [01:05<01:30, 3.26MB/s]\n",
      " 39%|###8      | 178M/458M [01:05<01:27, 3.36MB/s]\n",
      " 39%|###9      | 179M/458M [01:06<01:30, 3.25MB/s]\n",
      " 39%|###9      | 180M/458M [01:06<01:26, 3.38MB/s]\n",
      " 40%|###9      | 181M/458M [01:06<01:24, 3.42MB/s]\n",
      " 40%|###9      | 182M/458M [01:07<01:23, 3.46MB/s]\n",
      " 40%|###9      | 183M/458M [01:07<01:30, 3.19MB/s]\n",
      " 40%|####      | 184M/458M [01:07<01:25, 3.37MB/s]\n",
      " 40%|####      | 185M/458M [01:08<01:26, 3.32MB/s]\n",
      " 41%|####      | 186M/458M [01:08<01:37, 2.91MB/s]\n",
      " 41%|####      | 187M/458M [01:08<01:35, 2.98MB/s]\n",
      " 41%|####1     | 188M/458M [01:09<01:32, 3.08MB/s]\n",
      " 41%|####1     | 189M/458M [01:09<01:31, 3.08MB/s]\n",
      " 41%|####1     | 190M/458M [01:09<01:29, 3.14MB/s]\n",
      " 42%|####1     | 191M/458M [01:10<01:29, 3.11MB/s]"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d rtatman/glove-global-vectors-for-word-representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5Qjgi4V-58OE",
    "outputId": "dc62b104-4d37-4e76-e92c-903198bd88cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|####1     | 192M/458M [01:10<01:22, 3.40MB/s]\n",
      " 42%|####2     | 193M/458M [01:10<01:21, 3.41MB/s]\n",
      " 42%|####2     | 194M/458M [01:11<01:17, 3.57MB/s]\n",
      " 43%|####2     | 195M/458M [01:11<01:19, 3.47MB/s]\n",
      " 43%|####2     | 196M/458M [01:11<01:21, 3.38MB/s]\n",
      " 43%|####3     | 197M/458M [01:12<01:20, 3.42MB/s]\n",
      " 43%|####3     | 198M/458M [01:12<01:19, 3.45MB/s]\n",
      " 43%|####3     | 199M/458M [01:12<01:27, 3.11MB/s]\n",
      " 44%|####3     | 200M/458M [01:13<01:27, 3.10MB/s]\n",
      " 44%|####3     | 201M/458M [01:13<01:25, 3.15MB/s]\n",
      " 44%|####4     | 202M/458M [01:13<01:28, 3.05MB/s]\n",
      " 44%|####4     | 203M/458M [01:14<01:27, 3.05MB/s]\n",
      " 45%|####4     | 204M/458M [01:14<01:22, 3.22MB/s]\n",
      " 45%|####4     | 205M/458M [01:14<01:22, 3.22MB/s]\n",
      " 45%|####4     | 206M/458M [01:15<01:20, 3.30MB/s]\n",
      " 45%|####5     | 207M/458M [01:15<01:17, 3.40MB/s]\n",
      " 45%|####5     | 208M/458M [01:15<01:17, 3.39MB/s]\n",
      " 46%|####5     | 209M/458M [01:15<01:20, 3.24MB/s]\n",
      " 46%|####5     | 210M/458M [01:16<01:14, 3.51MB/s]\n",
      " 46%|####6     | 211M/458M [01:16<01:16, 3.37MB/s]\n",
      " 46%|####6     | 212M/458M [01:16<01:15, 3.40MB/s]\n",
      " 47%|####6     | 213M/458M [01:17<01:15, 3.39MB/s]\n",
      " 47%|####6     | 214M/458M [01:17<01:20, 3.18MB/s]\n",
      " 47%|####6     | 215M/458M [01:17<01:16, 3.34MB/s]\n",
      " 47%|####7     | 216M/458M [01:18<01:20, 3.13MB/s]\n",
      " 47%|####7     | 217M/458M [01:18<01:20, 3.12MB/s]\n",
      " 48%|####7     | 218M/458M [01:18<01:20, 3.11MB/s]\n",
      " 48%|####7     | 219M/458M [01:19<01:16, 3.29MB/s]\n",
      " 48%|####8     | 220M/458M [01:19<01:15, 3.29MB/s]\n",
      " 48%|####8     | 221M/458M [01:19<01:11, 3.45MB/s]\n",
      " 48%|####8     | 222M/458M [01:20<01:12, 3.40MB/s]\n",
      " 49%|####8     | 223M/458M [01:20<01:11, 3.43MB/s]\n",
      " 49%|####8     | 224M/458M [01:20<01:11, 3.44MB/s]\n",
      " 49%|####9     | 225M/458M [01:20<01:11, 3.41MB/s]\n",
      " 49%|####9     | 226M/458M [01:21<01:10, 3.44MB/s]\n",
      " 50%|####9     | 227M/458M [01:21<01:12, 3.36MB/s]\n",
      " 50%|####9     | 228M/458M [01:21<01:10, 3.44MB/s]\n",
      " 50%|#####     | 229M/458M [01:22<01:09, 3.43MB/s]\n",
      " 50%|#####     | 230M/458M [01:22<01:10, 3.38MB/s]\n",
      " 50%|#####     | 231M/458M [01:22<01:13, 3.25MB/s]\n",
      " 51%|#####     | 232M/458M [01:23<01:16, 3.11MB/s]\n",
      " 51%|#####     | 233M/458M [01:23<01:22, 2.87MB/s]\n",
      " 51%|#####1    | 234M/458M [01:24<01:24, 2.77MB/s]\n",
      " 51%|#####1    | 235M/458M [01:24<01:24, 2.77MB/s]\n",
      " 52%|#####1    | 236M/458M [01:24<01:15, 3.08MB/s]\n",
      " 52%|#####1    | 237M/458M [01:25<01:10, 3.29MB/s]\n",
      " 52%|#####1    | 238M/458M [01:25<01:09, 3.33MB/s]\n",
      " 52%|#####2    | 239M/458M [01:25<01:08, 3.33MB/s]\n",
      " 52%|#####2    | 240M/458M [01:25<01:08, 3.36MB/s]\n",
      " 53%|#####2    | 241M/458M [01:26<01:06, 3.42MB/s]\n",
      " 53%|#####2    | 242M/458M [01:26<01:04, 3.49MB/s]\n",
      " 53%|#####3    | 243M/458M [01:26<01:04, 3.49MB/s]\n",
      " 53%|#####3    | 244M/458M [01:27<01:06, 3.38MB/s]\n",
      " 54%|#####3    | 245M/458M [01:27<01:04, 3.45MB/s]\n",
      " 54%|#####3    | 246M/458M [01:27<01:04, 3.44MB/s]\n",
      " 54%|#####3    | 247M/458M [01:28<01:04, 3.41MB/s]\n",
      " 54%|#####4    | 248M/458M [01:28<01:11, 3.10MB/s]\n",
      " 54%|#####4    | 249M/458M [01:28<01:08, 3.20MB/s]\n",
      " 55%|#####4    | 250M/458M [01:29<01:05, 3.30MB/s]\n",
      " 55%|#####4    | 251M/458M [01:29<01:06, 3.28MB/s]\n",
      " 55%|#####5    | 252M/458M [01:29<01:04, 3.36MB/s]\n",
      " 55%|#####5    | 253M/458M [01:29<01:02, 3.43MB/s]\n",
      " 55%|#####5    | 254M/458M [01:30<01:02, 3.41MB/s]\n",
      " 56%|#####5    | 255M/458M [01:30<01:00, 3.50MB/s]\n",
      " 56%|#####5    | 256M/458M [01:30<01:00, 3.49MB/s]\n",
      " 56%|#####6    | 257M/458M [01:31<01:01, 3.40MB/s]\n",
      " 56%|#####6    | 258M/458M [01:31<01:03, 3.29MB/s]\n",
      " 57%|#####6    | 259M/458M [01:31<01:02, 3.35MB/s]\n",
      " 57%|#####6    | 260M/458M [01:32<01:00, 3.43MB/s]\n",
      " 57%|#####6    | 261M/458M [01:32<00:59, 3.46MB/s]\n",
      " 57%|#####7    | 262M/458M [01:32<01:02, 3.31MB/s]\n",
      " 57%|#####7    | 263M/458M [01:33<00:58, 3.49MB/s]\n",
      " 58%|#####7    | 264M/458M [01:33<01:02, 3.26MB/s]\n",
      " 58%|#####7    | 265M/458M [01:33<01:05, 3.09MB/s]\n",
      " 58%|#####8    | 266M/458M [01:34<01:10, 2.86MB/s]\n",
      " 58%|#####8    | 267M/458M [01:34<01:05, 3.05MB/s]\n",
      " 59%|#####8    | 268M/458M [01:34<01:01, 3.25MB/s]\n",
      " 59%|#####8    | 269M/458M [01:35<01:01, 3.22MB/s]\n",
      " 59%|#####8    | 270M/458M [01:35<00:57, 3.46MB/s]\n",
      " 59%|#####9    | 271M/458M [01:35<01:05, 3.01MB/s]\n",
      " 59%|#####9    | 272M/458M [01:36<01:00, 3.22MB/s]\n",
      " 60%|#####9    | 273M/458M [01:36<01:01, 3.15MB/s]\n",
      " 60%|#####9    | 274M/458M [01:36<00:58, 3.30MB/s]\n",
      " 60%|######    | 275M/458M [01:37<00:58, 3.25MB/s]\n",
      " 60%|######    | 276M/458M [01:37<00:57, 3.34MB/s]\n",
      " 60%|######    | 277M/458M [01:37<01:02, 3.04MB/s]\n",
      " 61%|######    | 278M/458M [01:38<00:56, 3.35MB/s]\n",
      " 61%|######    | 279M/458M [01:38<00:58, 3.23MB/s]\n",
      " 61%|######1   | 280M/458M [01:38<00:53, 3.46MB/s]\n",
      " 61%|######1   | 281M/458M [01:38<00:58, 3.19MB/s]\n",
      " 62%|######1   | 282M/458M [01:39<01:04, 2.87MB/s]\n",
      " 62%|######1   | 283M/458M [01:39<01:05, 2.81MB/s]\n",
      " 62%|######2   | 284M/458M [01:40<01:05, 2.77MB/s]\n",
      " 62%|######2   | 285M/458M [01:40<01:04, 2.81MB/s]\n",
      " 62%|######2   | 286M/458M [01:40<00:57, 3.13MB/s]\n",
      " 63%|######2   | 287M/458M [01:41<00:52, 3.39MB/s]\n",
      " 63%|######2   | 288M/458M [01:41<00:53, 3.33MB/s]\n",
      " 63%|######3   | 289M/458M [01:41<00:53, 3.31MB/s]\n",
      " 63%|######3   | 290M/458M [01:42<00:53, 3.30MB/s]\n",
      " 64%|######3   | 291M/458M [01:42<00:54, 3.24MB/s]\n",
      " 64%|######3   | 292M/458M [01:42<00:49, 3.50MB/s]\n",
      " 64%|######3   | 293M/458M [01:42<00:50, 3.43MB/s]\n",
      " 64%|######4   | 294M/458M [01:43<00:49, 3.46MB/s]\n",
      " 64%|######4   | 295M/458M [01:43<00:58, 2.94MB/s]\n",
      " 65%|######4   | 296M/458M [01:44<01:00, 2.79MB/s]\n",
      " 65%|######4   | 297M/458M [01:44<01:04, 2.63MB/s]\n",
      " 65%|######5   | 298M/458M [01:45<01:11, 2.36MB/s]\n",
      " 65%|######5   | 299M/458M [01:45<01:08, 2.44MB/s]\n",
      " 66%|######5   | 300M/458M [01:45<01:00, 2.74MB/s]\n",
      " 66%|######5   | 301M/458M [01:46<00:52, 3.11MB/s]\n",
      " 66%|######5   | 302M/458M [01:46<00:52, 3.14MB/s]\n",
      " 66%|######6   | 303M/458M [01:46<00:53, 3.03MB/s]\n",
      " 66%|######6   | 304M/458M [01:47<00:52, 3.10MB/s]\n",
      " 67%|######6   | 305M/458M [01:47<00:51, 3.10MB/s]\n",
      " 67%|######6   | 306M/458M [01:47<00:51, 3.07MB/s]\n",
      " 67%|######7   | 307M/458M [01:48<00:49, 3.20MB/s]\n",
      " 67%|######7   | 308M/458M [01:48<00:47, 3.34MB/s]\n",
      " 67%|######7   | 309M/458M [01:48<00:48, 3.22MB/s]\n",
      " 68%|######7   | 310M/458M [01:49<00:50, 3.08MB/s]\n",
      " 68%|######7   | 311M/458M [01:49<00:50, 3.08MB/s]\n",
      " 68%|######8   | 312M/458M [01:49<00:47, 3.21MB/s]\n",
      " 68%|######8   | 313M/458M [01:50<00:46, 3.24MB/s]\n",
      " 69%|######8   | 314M/458M [01:50<00:45, 3.32MB/s]\n",
      " 69%|######8   | 315M/458M [01:50<00:44, 3.35MB/s]\n",
      " 69%|######9   | 316M/458M [01:50<00:43, 3.42MB/s]\n",
      " 69%|######9   | 317M/458M [01:51<00:44, 3.36MB/s]\n",
      " 69%|######9   | 318M/458M [01:51<00:44, 3.33MB/s]\n",
      " 70%|######9   | 319M/458M [01:51<00:45, 3.21MB/s]\n",
      " 70%|######9   | 320M/458M [01:52<00:42, 3.43MB/s]\n",
      " 70%|#######   | 321M/458M [01:52<00:40, 3.53MB/s]\n",
      " 70%|#######   | 322M/458M [01:52<00:41, 3.42MB/s]\n",
      " 71%|#######   | 323M/458M [01:53<00:42, 3.35MB/s]\n",
      " 71%|#######   | 324M/458M [01:53<00:41, 3.42MB/s]\n",
      " 71%|#######   | 325M/458M [01:53<00:40, 3.41MB/s]\n",
      " 71%|#######1  | 326M/458M [01:54<00:43, 3.20MB/s]\n",
      " 71%|#######1  | 327M/458M [01:54<00:47, 2.88MB/s]\n",
      " 72%|#######1  | 328M/458M [01:54<00:50, 2.72MB/s]\n",
      " 72%|#######1  | 329M/458M [01:55<00:44, 3.03MB/s]\n",
      " 72%|#######2  | 330M/458M [01:55<00:42, 3.19MB/s]\n",
      " 72%|#######2  | 331M/458M [01:55<00:40, 3.28MB/s]\n",
      " 73%|#######2  | 332M/458M [01:56<00:41, 3.22MB/s]\n",
      " 73%|#######2  | 333M/458M [01:56<00:40, 3.22MB/s]\n",
      " 73%|#######2  | 334M/458M [01:56<00:42, 3.07MB/s]\n",
      " 73%|#######3  | 335M/458M [01:57<00:41, 3.09MB/s]\n",
      " 73%|#######3  | 336M/458M [01:57<00:40, 3.17MB/s]\n",
      " 74%|#######3  | 337M/458M [01:57<00:38, 3.29MB/s]\n",
      " 74%|#######3  | 338M/458M [01:58<00:43, 2.92MB/s]\n",
      " 74%|#######4  | 339M/458M [01:58<00:41, 3.03MB/s]\n",
      " 74%|#######4  | 340M/458M [01:58<00:40, 3.07MB/s]\n",
      " 74%|#######4  | 341M/458M [01:59<00:42, 2.87MB/s]\n",
      " 75%|#######4  | 342M/458M [02:01<01:41, 1.19MB/s]\n",
      " 75%|#######4  | 343M/458M [02:01<01:19, 1.52MB/s]\n",
      " 75%|#######5  | 344M/458M [02:01<01:06, 1.80MB/s]\n",
      " 75%|#######5  | 345M/458M [02:02<00:58, 2.02MB/s]\n",
      " 76%|#######5  | 346M/458M [02:02<00:52, 2.25MB/s]\n",
      " 76%|#######5  | 347M/458M [02:02<00:46, 2.50MB/s]\n",
      " 76%|#######5  | 348M/458M [02:03<00:48, 2.39MB/s]\n",
      " 76%|#######6  | 349M/458M [02:03<00:42, 2.70MB/s]\n",
      " 76%|#######6  | 350M/458M [02:04<00:50, 2.23MB/s]\n",
      " 77%|#######6  | 351M/458M [02:04<00:46, 2.40MB/s]\n",
      " 77%|#######6  | 352M/458M [02:05<00:42, 2.63MB/s]\n",
      " 77%|#######7  | 353M/458M [02:05<00:37, 2.90MB/s]\n",
      " 77%|#######7  | 354M/458M [02:05<00:40, 2.68MB/s]\n",
      " 78%|#######7  | 355M/458M [02:06<00:38, 2.77MB/s]\n",
      " 78%|#######7  | 356M/458M [02:06<00:37, 2.85MB/s]\n",
      " 78%|#######7  | 357M/458M [02:06<00:34, 3.08MB/s]\n",
      " 78%|#######8  | 358M/458M [02:07<00:32, 3.19MB/s]\n",
      " 78%|#######8  | 359M/458M [02:07<00:32, 3.23MB/s]\n",
      " 79%|#######8  | 360M/458M [02:07<00:33, 3.07MB/s]\n",
      " 79%|#######8  | 361M/458M [02:08<00:32, 3.13MB/s]\n",
      " 79%|#######9  | 362M/458M [02:08<00:31, 3.18MB/s]\n",
      " 79%|#######9  | 363M/458M [02:08<00:30, 3.21MB/s]\n",
      " 79%|#######9  | 364M/458M [02:09<00:30, 3.19MB/s]\n",
      " 80%|#######9  | 365M/458M [02:09<00:32, 3.04MB/s]\n",
      " 80%|#######9  | 366M/458M [02:09<00:32, 2.99MB/s]\n",
      " 80%|########  | 367M/458M [02:10<00:32, 2.93MB/s]\n",
      " 80%|########  | 368M/458M [02:10<00:31, 3.02MB/s]\n",
      " 81%|########  | 369M/458M [02:10<00:29, 3.13MB/s]\n",
      " 81%|########  | 370M/458M [02:11<00:28, 3.20MB/s]\n",
      " 81%|########1 | 371M/458M [02:11<00:29, 3.10MB/s]\n",
      " 81%|########1 | 372M/458M [02:11<00:28, 3.12MB/s]\n",
      " 81%|########1 | 373M/458M [02:12<00:28, 3.09MB/s]\n",
      " 82%|########1 | 374M/458M [02:12<00:27, 3.15MB/s]\n",
      " 82%|########1 | 375M/458M [02:12<00:27, 3.14MB/s]\n",
      " 82%|########2 | 376M/458M [02:13<00:26, 3.24MB/s]\n",
      " 82%|########2 | 377M/458M [02:13<00:25, 3.39MB/s]\n",
      " 83%|########2 | 378M/458M [02:13<00:26, 3.15MB/s]\n",
      " 83%|########2 | 379M/458M [02:14<00:26, 3.10MB/s]\n",
      " 83%|########2 | 380M/458M [02:14<00:34, 2.37MB/s]\n",
      " 83%|########3 | 381M/458M [02:15<00:32, 2.50MB/s]\n",
      " 83%|########3 | 382M/458M [02:15<00:30, 2.57MB/s]\n",
      " 84%|########3 | 383M/458M [02:15<00:29, 2.64MB/s]\n",
      " 84%|########3 | 384M/458M [02:16<00:31, 2.45MB/s]\n",
      " 84%|########4 | 385M/458M [02:16<00:32, 2.32MB/s]\n",
      " 84%|########4 | 386M/458M [02:17<00:30, 2.44MB/s]\n",
      " 85%|########4 | 387M/458M [02:17<00:27, 2.67MB/s]\n",
      " 85%|########4 | 388M/458M [02:18<00:29, 2.47MB/s]\n",
      " 85%|########4 | 389M/458M [02:18<00:29, 2.46MB/s]\n",
      " 85%|########5 | 390M/458M [02:18<00:26, 2.68MB/s]\n",
      " 85%|########5 | 391M/458M [02:19<00:26, 2.63MB/s]\n",
      " 86%|########5 | 392M/458M [02:19<00:24, 2.82MB/s]\n",
      " 86%|########5 | 393M/458M [02:20<00:24, 2.75MB/s]\n",
      " 86%|########6 | 394M/458M [02:20<00:21, 3.16MB/s]\n",
      " 86%|########6 | 395M/458M [02:20<00:22, 2.91MB/s]\n",
      " 86%|########6 | 396M/458M [02:20<00:22, 2.95MB/s]\n",
      " 87%|########6 | 397M/458M [02:21<00:19, 3.28MB/s]\n",
      " 87%|########6 | 398M/458M [02:21<00:20, 3.09MB/s]\n",
      " 87%|########7 | 399M/458M [02:21<00:18, 3.35MB/s]\n",
      " 87%|########7 | 400M/458M [02:22<00:21, 2.80MB/s]\n",
      " 88%|########7 | 401M/458M [02:22<00:20, 2.98MB/s]\n",
      " 88%|########7 | 402M/458M [02:22<00:17, 3.33MB/s]\n",
      " 88%|########8 | 403M/458M [02:23<00:17, 3.24MB/s]\n",
      " 88%|########8 | 404M/458M [02:23<00:17, 3.25MB/s]\n",
      " 88%|########8 | 405M/458M [02:24<00:19, 2.80MB/s]\n",
      " 89%|########8 | 406M/458M [02:25<00:33, 1.64MB/s]\n",
      " 89%|########8 | 407M/458M [02:25<00:26, 2.01MB/s]\n",
      " 89%|########9 | 408M/458M [02:25<00:23, 2.25MB/s]\n",
      " 89%|########9 | 409M/458M [02:26<00:21, 2.34MB/s]\n",
      " 90%|########9 | 410M/458M [02:27<00:26, 1.88MB/s]\n",
      " 90%|########9 | 411M/458M [02:27<00:22, 2.21MB/s]\n",
      " 90%|########9 | 412M/458M [02:27<00:19, 2.43MB/s]\n",
      " 90%|######### | 413M/458M [02:28<00:18, 2.51MB/s]\n",
      " 90%|######### | 414M/458M [02:28<00:16, 2.71MB/s]\n",
      " 91%|######### | 415M/458M [02:28<00:15, 2.83MB/s]\n",
      " 91%|######### | 416M/458M [02:29<00:15, 2.82MB/s]\n",
      " 91%|#########1| 417M/458M [02:29<00:14, 2.87MB/s]\n",
      " 91%|#########1| 418M/458M [02:29<00:13, 3.08MB/s]\n",
      " 91%|#########1| 419M/458M [02:30<00:12, 3.25MB/s]\n",
      " 92%|#########1| 420M/458M [02:30<00:11, 3.35MB/s]\n",
      " 92%|#########1| 421M/458M [02:30<00:11, 3.42MB/s]\n",
      " 92%|#########2| 422M/458M [02:30<00:10, 3.44MB/s]\n",
      " 92%|#########2| 423M/458M [02:31<00:10, 3.45MB/s]\n",
      " 93%|#########2| 424M/458M [02:31<00:10, 3.45MB/s]\n",
      " 93%|#########2| 425M/458M [02:31<00:09, 3.47MB/s]\n",
      " 93%|#########3| 426M/458M [02:32<00:09, 3.51MB/s]\n",
      " 93%|#########3| 427M/458M [02:32<00:09, 3.52MB/s]\n",
      " 93%|#########3| 428M/458M [02:32<00:09, 3.47MB/s]\n",
      " 94%|#########3| 429M/458M [02:33<00:08, 3.49MB/s]\n",
      " 94%|#########3| 430M/458M [02:33<00:08, 3.49MB/s]\n",
      " 94%|#########4| 431M/458M [02:33<00:08, 3.52MB/s]\n",
      " 94%|#########4| 432M/458M [02:34<00:08, 3.23MB/s]\n",
      " 95%|#########4| 433M/458M [02:34<00:08, 3.16MB/s]\n",
      " 95%|#########4| 434M/458M [02:34<00:07, 3.24MB/s]\n",
      " 95%|#########4| 435M/458M [02:34<00:07, 3.28MB/s]\n",
      " 95%|#########5| 436M/458M [02:35<00:06, 3.31MB/s]\n",
      " 95%|#########5| 437M/458M [02:35<00:06, 3.41MB/s]\n",
      " 96%|#########5| 438M/458M [02:35<00:06, 3.40MB/s]\n",
      " 96%|#########5| 439M/458M [02:36<00:05, 3.52MB/s]\n",
      " 96%|#########6| 440M/458M [02:36<00:05, 3.52MB/s]\n",
      " 96%|#########6| 441M/458M [02:36<00:05, 3.52MB/s]\n",
      " 97%|#########6| 442M/458M [02:37<00:04, 3.53MB/s]\n",
      " 97%|#########6| 443M/458M [02:37<00:04, 3.41MB/s]\n",
      " 97%|#########6| 444M/458M [02:37<00:04, 2.95MB/s]\n",
      " 97%|#########7| 445M/458M [02:38<00:04, 3.35MB/s]\n",
      " 97%|#########7| 446M/458M [02:38<00:03, 3.32MB/s]\n",
      " 98%|#########7| 447M/458M [02:38<00:03, 3.24MB/s]\n",
      " 98%|#########7| 448M/458M [02:39<00:03, 3.20MB/s]\n",
      " 98%|#########8| 449M/458M [02:39<00:02, 3.18MB/s]\n",
      " 98%|#########8| 450M/458M [02:39<00:02, 2.95MB/s]\n",
      " 98%|#########8| 451M/458M [02:40<00:02, 3.31MB/s]\n",
      " 99%|#########8| 452M/458M [02:40<00:01, 3.48MB/s]\n",
      " 99%|#########8| 453M/458M [02:40<00:01, 3.47MB/s]\n",
      " 99%|#########9| 454M/458M [02:40<00:01, 3.42MB/s]\n",
      " 99%|#########9| 455M/458M [02:41<00:00, 3.51MB/s]\n",
      "100%|#########9| 456M/458M [02:41<00:00, 3.46MB/s]\n",
      "100%|#########9| 457M/458M [02:41<00:00, 3.46MB/s]\n",
      "100%|##########| 458M/458M [02:42<00:00, 3.38MB/s]\n",
      "100%|##########| 458M/458M [02:42<00:00, 2.96MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "file_name = \"glove-global-vectors-for-word-representation.zip\"\n",
    "\n",
    "with ZipFile(file_name, \"r\") as files:\n",
    "  files.extractall()\n",
    "  print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Hyo1z3f59KX"
   },
   "outputs": [],
   "source": [
    "embedding_dict = {}\n",
    "\n",
    "file = open(\"glove.6B.100d.txt\", encoding=\"utf8\")\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    words = values[0]\n",
    "    vectors = np.asarray(values[1:], \"float32\")\n",
    "    embedding_dict[words] = vectors\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting virtualenv\n",
      "  Downloading virtualenv-20.0.18-py2.py3-none-any.whl (4.6 MB)\n",
      "Requirement already satisfied: six<2,>=1.9.0 in c:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from virtualenv) (1.14.0)\n",
      "Collecting filelock<4,>=3.0.0\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting distlib<1,>=0.3.0\n",
      "  Downloading distlib-0.3.0.zip (571 kB)\n",
      "Collecting appdirs<2,>=1.4.3\n",
      "  Downloading appdirs-1.4.3-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: distlib\n",
      "  Building wheel for distlib (setup.py): started\n",
      "  Building wheel for distlib (setup.py): finished with status 'done'\n",
      "  Created wheel for distlib: filename=distlib-0.3.0-py3-none-any.whl size=340432 sha256=2468e27bb85958d01bdbff43e2c22121b95b1235fd8db6fe63b871952c81d1ff\n",
      "  Stored in directory: c:\\users\\nathasya\\appdata\\local\\pip\\cache\\wheels\\eb\\4e\\d2\\a903d4184fb49e4ac06474d65715b129aee13d69f7d227e78e\n",
      "Successfully built distlib\n",
      "Installing collected packages: filelock, distlib, appdirs, virtualenv\n",
      "Successfully installed appdirs-1.4.3 distlib-0.3.0 filelock-3.0.12 virtualenv-20.0.18\n"
     ]
    }
   ],
   "source": [
    "!pip install virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: failed to find interpreter for Builtin discover of python_spec='python3.6'\n"
     ]
    }
   ],
   "source": [
    "!virtualenv -p python3.6 Python_3_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8pCn2N5v5-C2",
    "outputId": "63058aa1-7aef-4fa9-a6bf-b4622524a6ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-254-938327823863>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\backend\\load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfdev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Perform pre-load sanity checks in order to produce a more actionable error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# than we get from an error during SWIG import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mself_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreload_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nathasya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\u001b[0m in \u001b[0;36mpreload_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m           \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdll_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         raise ImportError(\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[1;34m\"Could not find the DLL(s) %r. TensorFlow requires that these DLLs \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;34m\"be installed in a directory that is named in your %%PATH%% \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwISJJEF5_FX"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequence = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "text_pad = pad_sequences(sequence, maxlen = 50, truncating = \"post\", padding = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNlIIGG95_6J"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "embedding_mat = np.zeros((num_words, 100))\n",
    "\n",
    "# print(word_index)\n",
    "\n",
    "for word, idx in word_index.items():\n",
    "  if idx > num_words:\n",
    "    continue\n",
    "  \n",
    "  embedding_vec = embedding_dict.get(word)\n",
    "  if embedding_vec is not None:\n",
    "    embedding_mat[idx] = embedding_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLein7BElnFF"
   },
   "source": [
    "## Modelling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owMKfVFZlnFH"
   },
   "source": [
    "### Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Teb1IvTWVZQu"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "rf = rf.fit(train_features, y_train)\n",
    "rf_pred = rf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "KhckIychVcHa",
    "outputId": "7879e1da-d9ed-4e3b-97a2-007a0652f282"
   },
   "outputs": [],
   "source": [
    "akurasi = accuracy_score(y_test, rf_pred)\n",
    "presisi = precision_score(y_test, rf_pred)\n",
    "recall = recall_score(y_test,rf_pred)\n",
    "\n",
    "print(\"Akurasi : {}\".format(akurasi))\n",
    "print(\"Precision : {}\".format(presisi))\n",
    "print(\"Recall : {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQUp6IzvlnFH"
   },
   "source": [
    "### Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEFsc280VdVe"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_features, y_train)\n",
    "nb_pred = nb.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "1l1kbi1HVeXl",
    "outputId": "27c49c4e-a945-437f-cf1f-b59a278dc7cb"
   },
   "outputs": [],
   "source": [
    "akurasi = accuracy_score(y_test, nb_pred)\n",
    "presisi = precision_score(y_test, nb_pred)\n",
    "recall = recall_score(y_test,nb_pred)\n",
    "\n",
    "print(\"Akurasi : {}\".format(akurasi))\n",
    "print(\"Precision : {}\".format(presisi))\n",
    "print(\"Recall : {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7h9mJ8EVhud"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "RBEgyMpIXFc3",
    "outputId": "d2637f10-6ad5-4958-b145-9044154071db"
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reglog = LogisticRegression()\n",
    "reglog = reglog.fit(train_features, y_train)\n",
    "reglog_pred = reglog.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "jr_0Yt-hXFIR",
    "outputId": "a6eae6d1-590a-412e-919f-3d710a90160d"
   },
   "outputs": [],
   "source": [
    "akurasi = accuracy_score(y_test, reglog_pred)\n",
    "presisi = precision_score(y_test, reglog_pred)\n",
    "recall = recall_score(y_test,reglog_pred)\n",
    "\n",
    "print(\"Akurasi : {}\".format(akurasi))\n",
    "print(\"Precision : {}\".format(presisi))\n",
    "print(\"Recall : {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tkk-JxypVrXw"
   },
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "TUvHpNSuXEmn",
    "outputId": "b19b40be-111f-461e-863e-2d3e0777efba"
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "voa6KIpQXERr"
   },
   "outputs": [],
   "source": [
    "#LigthGBM\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "lgbm = lgbm.fit(train_features, y_train)\n",
    "lgbm_pred = lgbm.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "J_uTwAJ5XEAX",
    "outputId": "740138cf-85df-4951-cc22-96ebe5291b6e"
   },
   "outputs": [],
   "source": [
    "akurasi = accuracy_score(y_test, lgbm_pred)\n",
    "presisi = precision_score(y_test, lgbm_pred)\n",
    "recall = recall_score(y_test,lgbm_pred)\n",
    "\n",
    "print(\"Akurasi : {}\".format(akurasi))\n",
    "print(\"Precision : {}\".format(presisi))\n",
    "print(\"Recall : {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BwcD6eBlnFI"
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mOZWQzywXGFr",
    "outputId": "fdbec4f0-f1b7-4581-d57d-ca3b3b870c8f"
   },
   "outputs": [],
   "source": [
    "!pip install constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ciu0wM3IXxnN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from tensorflow.python.keras.initializers import Constant\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "be2LhGM7Vxg5",
    "outputId": "77274324-f15c-424e-d660-f16700b15229"
   },
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "embedding = Embedding(num_words, 100,\n",
    "                      embeddings_initializer = Constant(embedding_mat), \n",
    "                      input_length = 50, trainable = False)\n",
    "\n",
    "model.add(embedding)\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(64, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rDwz5EsVxcP"
   },
   "outputs": [],
   "source": [
    "X = text_pad\n",
    "y = df[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "m1zgvCS9XnIb",
    "outputId": "66aa25d4-f25c-4d77-f321-c5e584020949"
   },
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_pad, y, test_size = 0.15)\n",
    "\n",
    "print(\"Dimension of X_train : {}\".format(X_train.shape))\n",
    "print(\"Dimension of X_test : {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "Qwb4_8_lXod2",
    "outputId": "cec72d4f-8594-4c35-cbc4-62fe43f4f578"
   },
   "outputs": [],
   "source": [
    "first = model.fit(x = X_train, y = y_train, batch_size = 4, epochs = 5, validation_data = (X_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bhSdXrTVXohx"
   },
   "outputs": [],
   "source": [
    "nn_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "oPZ1HcdJXrb9",
    "outputId": "630fc02a-be2f-49a3-f0a1-77836bfc910a"
   },
   "outputs": [],
   "source": [
    "akurasi = accuracy_score(y_test, nn_pred.round())\n",
    "presisi = precision_score(y_test, nn_pred.round())\n",
    "recall = recall_score(y_test, nn_pred.round())\n",
    "\n",
    "print(\"Akurasi : {}\".format(akurasi))\n",
    "print(\"Precision : {}\".format(presisi))\n",
    "print(\"Recall : {}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Fake_News.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
